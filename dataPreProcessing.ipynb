{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql imports\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.types as typ\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as fn\n",
    "\n",
    "#spark context\n",
    "from pyspark.context import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training dataframe\n",
    "labels_train= [('Store',typ.IntegerType()),\n",
    "              ('Dept',typ.IntegerType()),\n",
    "              ('Date',typ.DateType()),\n",
    "              ('Weekly_sales',typ.DoubleType()),\n",
    "              ('IsHoliday',typ.BooleanType())\n",
    "         ]\n",
    "\n",
    "\n",
    "schema_train = typ.StructType([\n",
    "typ.StructField(e[0], e[1], False) for e in labels_train\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_values = spark.read.csv('./train/train.csv', header=True,schema=schema_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Dept: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Weekly_sales: double (nullable = true)\n",
      " |-- IsHoliday: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv_values.printSchema()\n",
    "#train_csv_values.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      " |-- MarkDown1: string (nullable = true)\n",
      " |-- MarkDown2: string (nullable = true)\n",
      " |-- MarkDown3: string (nullable = true)\n",
      " |-- MarkDown4: string (nullable = true)\n",
      " |-- MarkDown5: string (nullable = true)\n",
      " |-- CPI: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      " |-- IsHoliday: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating feature dataframe\n",
    "labels_features= [('Store',typ.IntegerType()),\n",
    "              ('Date',typ.DateType()),\n",
    "              ('Temperature',typ.DoubleType()),\n",
    "            ('Fuel_Price',typ.DoubleType()),\n",
    "                  ('MarkDown1',typ.StringType()),\n",
    "                  ('MarkDown2',typ.StringType()),\n",
    "                  ('MarkDown3',typ.StringType()),\n",
    "                  ('MarkDown4',typ.StringType()),\n",
    "                  ('MarkDown5',typ.StringType()),\n",
    "                  ('CPI',typ.DoubleType()),\n",
    "                  ('Unemployment',typ.DoubleType()),\n",
    "              ('IsHoliday',typ.BooleanType())\n",
    "         ]\n",
    "schema_features= typ.StructType([\n",
    "typ.StructField(e[0], e[1], False) for e in labels_features\n",
    "])\n",
    "featuers_csv_values = spark.read.csv('./features/features.csv', header=True,schema=schema_features)\n",
    "featuers_csv_values.printSchema()\n",
    "#featuers_csv_values.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Size: integer (nullable = true)\n",
      "\n",
      "+-----+----+------+\n",
      "|Store|Type|  Size|\n",
      "+-----+----+------+\n",
      "|    1|   A|151315|\n",
      "|    2|   A|202307|\n",
      "|    3|   B| 37392|\n",
      "|    4|   A|205863|\n",
      "|    5|   B| 34875|\n",
      "+-----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating stores dataframe\n",
    "labels_stores= [('Store',typ.IntegerType()),\n",
    "              ('Type',typ.StringType()),\n",
    "              ('Size',typ.IntegerType())\n",
    "         ]\n",
    "schema_stores= typ.StructType([\n",
    "typ.StructField(e[0], e[1], False) for e in labels_stores\n",
    "])\n",
    "stores_csv_values = spark.read.csv('stores.csv', header=True,schema=schema_stores)\n",
    "stores_csv_values.printSchema()\n",
    "stores_csv_values.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store',\n",
       " 'Date',\n",
       " 'Temperature',\n",
       " 'Fuel_Price',\n",
       " 'MarkDown1',\n",
       " 'MarkDown2',\n",
       " 'MarkDown3',\n",
       " 'MarkDown4',\n",
       " 'MarkDown5',\n",
       " 'CPI',\n",
       " 'Unemployment',\n",
       " 'IsHoliday']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_values.createOrReplaceTempView(\"train_csv_values\")\n",
    "featuers_csv_values.createOrReplaceTempView(\"featuers_csv_values\")\n",
    "stores_csv_values.createOrReplaceTempView(\"stores_csv_values\")\n",
    "featuers_csv_values.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=spark.sql(\"\"\"select train_csv_values.Store,train_csv_values.Dept,stores_csv_values.Type,stores_csv_values.Size,\n",
    "train_csv_values.Date,train_csv_values.Weekly_Sales,\n",
    "featuers_csv_values.Temperature,featuers_csv_values.Fuel_Price,featuers_csv_values.CPI, featuers_csv_values.Unemployment, featuers_csv_values.MarkDown1, featuers_csv_values.MarkDown2, featuers_csv_values.MarkDown3, featuers_csv_values.MarkDown4, featuers_csv_values.MarkDown5,\n",
    "train_csv_values.IsHoliday from train_csv_values\n",
    "join featuers_csv_values on train_csv_values.Store=featuers_csv_values.Store and train_csv_values.Date=featuers_csv_values.Date\n",
    "Join stores_csv_values on train_csv_values.Store=stores_csv_values.Store\n",
    "where train_csv_values.Weekly_Sales>0\n",
    "\"\"\")\n",
    "#where train_csv_values.Store<=10 and train_csv_values.Dept<=15\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.toPandas()\\\n",
    ".to_csv('joined_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 420212\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing \n",
    "print('Count of rows: {0}'.format(data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 420212\n"
     ]
    }
   ],
   "source": [
    "print('Count of rows: {0}'.format(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of distinct records: 420212\n"
     ]
    }
   ],
   "source": [
    "print('Count of distinct records: {0}'\\\n",
    "      .format(df.select([c for c in df.columns]).distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------+------------+------------+--------------------+-------------------+------------------+-----------+--------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|Store_missing|Dept_missing|Type_missing|Size_missing|Date_missing|Weekly_Sales_missing|Temperature_missing|Fuel_Price_missing|CPI_missing|Unemployment_missing|MarkDown1_missing|MarkDown2_missing|MarkDown3_missing|MarkDown4_missing|MarkDown5_missing|IsHoliday_missing|\n",
      "+-------------+------------+------------+------------+------------+--------------------+-------------------+------------------+-----------+--------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|          0.0|         0.0|         0.0|         0.0|         0.0|                 0.0|                0.0|               0.0|        0.0|                 0.0|              0.0|              0.0|              0.0|              0.0|              0.0|              0.0|\n",
      "+-------------+------------+------------+------------+------------+--------------------+-------------------+------------------+-----------+--------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(*[\n",
    "(1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing') \\\n",
    "for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Dept: integer (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Size: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Weekly_Sales: double (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      " |-- CPI: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      " |-- MarkDown1: string (nullable = true)\n",
      " |-- MarkDown2: string (nullable = true)\n",
      " |-- MarkDown3: string (nullable = true)\n",
      " |-- MarkDown4: string (nullable = true)\n",
      " |-- MarkDown5: string (nullable = true)\n",
      " |-- IsHoliday: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
